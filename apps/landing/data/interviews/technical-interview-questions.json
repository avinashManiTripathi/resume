{
    "slug": "technical-interview-questions",
    "title": "Technical Interview Questions: CS Fundamentals & System Design (2026)",
    "description": "A deep dive into core computer science concepts. Top 50 questions covering Data Structures, Algorithms, System Design, Databases, and Networking for software engineering interviews.",
    "heroBadge": "CS Fundamentals: 50+ Q&A",
    "sections": [
        {
            "title": "1. Data Structures & Algorithms",
            "content": "**Q1: Explain the difference between an Array and a Linked List.**\nArrays store elements in contiguous memory locations, allowing for O(1) random access (by index). However, inserting or deleting elements in the middle requires shifting subsequent elements, making it an O(n) operation. Linked Lists consist of nodes where each node contains data and a pointer to the next node. They exist in non-contiguous memory. Insertions and deletions are O(1) if you have the pointer to the location, but accessing an element is O(n) because you must traverse from the head. Arrays are better for read-heavy operations; Linked Lists are better for write-heavy scenarios where memory is fragmented.\n\n**Q2: What is a Hash Table and how does it handle collisions?**\nA Hash Table implements an associative array abstract data type that maps keys to values. It uses a hash function to compute an index into an array of buckets or slots. Ideally, the hash function distributes keys uniformly. Collisions occur when two keys hash to the same index. Common resolution strategies include: 1) **Chaining**: Each bucket stores a linked list of entries that hash to the same index. 2) **Open Addressing**: Finding the next available slot using probing (linear, quadratic, or double hashing). Hash tables offer average O(1) search, insert, and delete.\n\n**Q3: Explain the concept of Big O notation.**\nBig O notation describes the upper bound of an algorithm's complexity (time or space) in terms of input size (n) as n approaches infinity. It classifies algorithms according to how their run time or space requirements grow. For example, O(1) is constant time (accessing an array index), O(log n) is logarithmic (binary search), O(n) is linear (iterating a list), O(n log n) is linearithmic (efficient sorts like mergesort), and O(n^2) is quadratic (nested loops). Understanding Big O is crucial for writing scalable code.\n\n**Q4: Stack vs. Queue.**\nA Stack is a LIFO (Last In, First Out) data structure, like a stack of plates. Push adds to the top, Pop removes from the top. Used in function call stacks and undo mechanisms. A Queue is a FIFO (First In, First Out) structure, like a line at a store. Enqueue adds to the rear, Dequeue removes from the front. Used in task scheduling, printer spooling, and Breadth-First Search (BFS).\n\n**Q5: How does Binary Search work?**\nBinary Search is an efficient algorithm for finding an item from a sorted list of items. It works by repeatedly dividing in half the portion of the list that could contain the item, until you've narrowed down the possible locations to just one. It compares the target value to the middle element of the array. If they match, its found. If the target is less than the middle, it searches the left half; otherwise, the right half. Time complexity is O(log n). Pre-requisite: The list *must* be sorted."
        },
        {
            "title": "2. System Design & Scalability",
            "content": "**Q6: What is Load Balancing?**\nLoad balancing distributes incoming network traffic across multiple servers (a server farm or server pool). This ensures no single server bears too much load, preventing it from becoming a single point of failure and improving responsiveness. Load balancers can operate at Layer 4 (Transport) or Layer 7 (Application). Algorithms include Round Robin, Least Connections, and IP Hash. They are critical for horizontal scaling.\n\n**Q7: Vertical Scaling vs. Horizontal Scaling.**\nVertical Scaling (Scaling Up) means adding more power (CPU, RAM) to an existing server. It's simple but has a finite limit (ceiling) and is expensive. Horizontal Scaling (Scaling Out) means adding more servers to the pool. It offers theoretically infinite scalability and redundancy but adds complexity in data consistency and management. Modern distributed systems prefer horizontal scaling.\n\n**Q8: What is CAP Theorem?**\nThe CAP theorem states that a distributed data store can effectively provide only two of the following three guarantees: **Consistency** (every read receives the most recent write or an error), **Availability** (every request receives a (non-error) response, without the guarantee that it contains the most recent write), and **Partition Tolerance** (the system continues to operate despite an arbitrary number of messages being dropped or delayed by the network between nodes). You usually trade Consistency for Availability (AP) or vice versa (CP) in the presence of a Partition (P).\n\n**Q9: SQL vs. NoSQL Databases.**\nSQL (Relational) databases (e.g., MySQL, PostgreSQL) use structured schemas and tables. They are best for complex queries, transactions (ACID context), and data integrity. NoSQL (Non-Relational) databases (e.g., MongoDB, Cassandra, Redis) are schema-less (document, key-value, graph). They are best for rapid development, managing large amounts of unstructured data, horizontal scaling, and high-throughput applications.\n\n**Q10: What is Caching?**\nCaching is a technique to store copies of data in a high-speed data storage layer (like RAM) so that future requests for that data can be served faster than strictly accessing the data's primary storage location. Common caching layers include Browser Cache, CDN (Content Delivery Network), API Gateway Cache, and Database Cache (Redis/Memcached). Caching reduces latency and database load but introduces the challenge of cache invalidation."
        },
        {
            "title": "3. Networking & Web Protocols",
            "content": "**Q11: What happens when you type a URL into a browser?**\n1. DNS Resolution: Browser checks cache, OS cache, then queries DNS server to convert domain (google.com) to IP address. 2. TCP Handshake: Browser initiates a TCP connection with the server (SYN, SYN-ACK, ACK). 3. TLS Handshake: If HTTPS, keys are exchanged to decrypt traffic. 4. HTTP Request: Browser sends GET request. 5. Server Response: Server processes request and sends back HTML/JSON. 6. Browser Rendering: Browser parses HTML, builds DOM, fetches CSS/JS, and paints the page.\n\n**Q12: HTTP vs. HTTPS.**\nHTTP (Hypertext Transfer Protocol) transmits data in plain text, making it vulnerable to eavesdropping. HTTPS (HTTP Secure) uses SSL/TLS encryption to secure the communication channel. It encrypts the request and response, ensuring confidentiality, integrity, and authentication. HTTPS is essential for any site handling user data and is a Google ranking factor.\n\n**Q13: What are RESTful APIs?**\nREST (Representational State Transfer) is an architectural style for designing networked applications. Key constraints include: Client-Server architecture, Statelessness (each request contains all info needed), Cacheability, Layered System, and Uniform Interface using standard HTTP methods (GET, POST, PUT, DELETE) and status codes. Resources are identified by URIs.\n\n**Q14: TCP vs. UDP.**\nTCP (Transmission Control Protocol) is connection-oriented and reliable. It guarantees packet delivery and order (via retransmission and sequencing), making it slower. Used for Web (HTTP), Email (SMTP), FTP. UDP (User Datagram Protocol) is connectionless and unreliable (\"fire and forget\"). It sends packets without handshake or checking for arrival. It is faster but allows packet loss. Used for real-time apps like Video Streaming, Gaming, VoIP.\n\n**Q15: What is CORS?**\nCross-Origin Resource Sharing (CORS) is a security mechanism that allows a web page from one domain (origin) to access resources from a server at a different domain. Browsers enforce the Same-Origin Policy by default. Servers must send specific headers (like `Access-Control-Allow-Origin`) to explicitly allow the browser to relax this security for specific requests."
        },
        {
            "title": "4. Operating Systems & Concurrency",
            "content": "**Q16: Process vs. Thread.**\nA Process is an independent program in execution with its own memory space. Processes do not share memory. A Thread is a lightweight unit of execution within a process. Threads within the same process share the same memory space (heap) but have their own stack. Context switching between threads is faster than between processes, but multithreading introduces synchronization issues (race conditions).\n\n**Q17: What is a Deadlock?**\nA deadlock is a situation in a multi-threaded environment where two or more threads are unable to proceed because each is waiting for the other to release a resource. It typically happens when four conditions (Coffman conditions) are met: Mutual Exclusion, Hold and Wait, No Preemption, and Circular Wait.\n\n**Q18: What is Virtual Memory?**\nVirtual Memory is a memory management capability of an OS that uses hardware and software to allow a computer to compensate for physical memory shortages by temporarily transferring data from RAM to disk storage (swap space). It gives applications the illusion of having a large, contiguous block of memory.\n\n**Q19: Compilers vs. Interpreters.**\nA Compiler (e.g., C++, Go) translates the entire source code into machine code (binary) at once before execution. It produces a standalone executable. An Interpreter (e.g., Python, Ruby) reads and executes the source code line-by-line at runtime. Compiled code is generally faster to run but slower to develop. Interpreted languages are more flexible/portable but slower in execution.\n\n**Q20: What is a Race Condition?**\nA race condition occurs when the behavior of software depends on the relative timing of events, such as the order in which threads are scheduled. If two threads try to modify a shared variable at the same time without proper synchronization (locks/mutexes), the final value depends on which thread finished last, leading to unpredictable bugs."
        },
        {
            "title": "5. Code & Design Patterns",
            "content": "**Q21: What is the Singleton Pattern?**\nSingleton is a creational design pattern that restricts the instantiation of a class to one single instance. It provides a global point of access to that instance. Used for Logging drivers, Database connections, or Configuration settings. However, it effectively introduces global state, which can make testing difficult.\n\n**Q22: Composition over Inheritance.**\nThis is a design principle that suggests it is better to build objects by combining simple, flexible objects (composition) rather than by creating deep class hierarchies (inheritance). Inheritance is rigid ('is-a' relationship) and fragile to changes in the parent class. Composition ('has-a' relationship) is more flexible and decoupled.\n\n**Q23: What is Dependency Injection?**\nDI is a technique where an object receives other objects that it depends on (dependencies) rather than creating them internally. This improves modularity, makes specific implementations swappable (e.g., swapping a real database for a mock one), and greatly facilitates Unit Testing. It is a form of Inversion of Control (IoC).\n\n**Q24: SOLID Principles.**\nAn acronym for five design principles for maintainable OO design: **S**ingle Responsibility (one reason to change), **O**pen/Closed (open for extension, closed for modification), **L**iskov Substitution (subtypes must be substitutable for base types), **I**nterface Segregation (many specific interfaces are better than one general one), **D**ependency Inversion (depend on abstractions, not concretions).\n\n**Q25: Monolithic vs. Microservices Architecture.**\nA Monolith is a single, unified application where all components (UI, Business Logic, DB access) are tightly coupled in one repository/process. Simple to deploy initially but hard to scale parts independently. Microservices break the app into small, independent services that communicate over a network (APIs). Complex to manage (devops, latency) but allows independent scaling, deployment, and technology choices."
        }
    ]
}